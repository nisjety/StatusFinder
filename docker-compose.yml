services:
  redis:
    image: redis:7.0-alpine
    container_name: discovery-redis
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data
    restart: unless-stopped
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3
      start_period: 5s
    # Enable keyspace notifications for enhanced monitoring
    command: redis-server --appendonly yes --notify-keyspace-events Ex

  scrapyd:
    build:
      context: ./apps/discovery
      dockerfile: Dockerfile
    image: discovery-scrapyd
    container_name: discovery-scrapyd
    ports:
      - "6800:6800"
    volumes:
      - ./apps/discovery/data:/app/data
      - ./apps/discovery/discovery:/app/discovery  # Mount source code for development
      - ./apps/discovery/screenshots:/app/screenshots  # Dedicated screenshots directory
      - scrapyd_eggs:/app/eggs
      - scrapyd_items:/app/items
      - scrapyd_logs:/app/logs
      - scrapyd_dbs:/app/dbs
    restart: unless-stopped
    environment:
      - DISCOVERY_ENV=production
      - SCRAPYD_USERNAME=admin
      - SCRAPYD_PASSWORD=scrapyd123
      - PYTHONPATH=/app
      - SCRAPY_SETTINGS_MODULE=discovery.settings
      # Deployment settings
      - DEPLOY_PROJECT=discovery
      - DEPLOY_VERSION=1.0
      - DEPLOY_SPIDERS=true
      # Redis cache settings
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - HTTP_CACHE_TTL=3600
      # MongoDB settings
      - MONGODB_URI=mongodb://mongodb:27017
      - MONGODB_DB_NAME=discovery
      # Twisted reactor and Playwright settings
      - TWISTED_REACTOR=twisted.internet.asyncioreactor.AsyncioSelectorReactor
      - PLAYWRIGHT_BROWSER_TYPE=chromium
      - PLAYWRIGHT_LAUNCH_OPTIONS={"headless":true}
    depends_on:
      redis:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "-u", "admin:scrapyd123", "http://localhost:6800/daemonstatus.json"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s
    networks:
      - discovery-network
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M
  
  webhook:
    build:
      context: ./apps/discovery
      dockerfile: Dockerfile.webhook
    image: discovery-webhook
    container_name: discovery-webhook
    ports:
      - "8000:8000"
    depends_on:
      scrapyd:
        condition: service_healthy
      redis:
        condition: service_healthy
    restart: unless-stopped
    environment:
      - SCRAPYD_URL=http://scrapyd:6800
      - PROJECT_NAME=Discovery
      - DEFAULT_SPIDER=quick
      # Redis cache settings
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      - HTTP_CACHE_TTL=3600
    volumes:
      - ./apps/discovery/webhook_handler.py:/app/webhook_handler.py
      - ./apps/discovery/data/logs:/app/logs
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # SIMPLIFIED MongoDB without authentication for development
  mongodb:
    image: mongo:6.0
    container_name: discovery-mongodb
    volumes:
      - mongodb_data:/data/db
    ports:
      - "27017:27017"
    restart: unless-stopped
    # NO AUTHENTICATION for simplicity
    command: mongod --bind_ip_all
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')", "--quiet"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # SIMPLIFIED RabbitMQ with consistent credentials
  rabbitmq:
    image: rabbitmq:3.11-management-alpine
    container_name: discovery-rabbitmq
    volumes:
      - rabbitmq_data:/var/lib/rabbitmq
      - ./apps/rabbitmq/init.sh:/docker-entrypoint-initdb.d/init.sh:ro
    ports:
      - "5672:5672"  # AMQP port
      - "15672:15672"  # Management UI
    restart: unless-stopped
    environment:
      - RABBITMQ_DEFAULT_USER=admin
      - RABBITMQ_DEFAULT_PASS=rabbitmq123
      - RABBITMQ_DEFAULT_VHOST=discovery
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "rabbitmqctl", "status"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  scheduler:
    build: 
      context: .
      dockerfile: apps/scheduler/Dockerfile
    image: discoverybot/scheduler:latest
    container_name: discovery-scheduler
    ports:
      - '8001:8001'
    environment:
      # SIMPLIFIED MongoDB connection (no auth)
      - MONGO_URI=mongodb://mongodb:27017/discovery
      - MONGO_DB_NAME=discovery
      - REDIS_HOST=redis
      - REDIS_PORT=6379
      - REDIS_DB=0
      # CONSISTENT RabbitMQ credentials
      - RABBITMQ_URI=amqp://admin:rabbitmq123@rabbitmq:5672/discovery
      
      # Scrapyd settings with CONSISTENT credentials
      - SCRAPYD_URL=http://scrapyd:6800
      - SCRAPYD_USERNAME=admin
      - SCRAPYD_PASSWORD=scrapyd123
      - SCRAPYD_PROJECT=discovery
      
      # Enhanced settings for optimized architecture
      - SSE_MAX_DURATION=600
      - SSE_HEARTBEAT_INTERVAL=2
      - RESULTS_FETCH_TIMEOUT=30
      - CRAWL_CACHE_TTL=3600
      - HTTP_CACHE_TTL=3600
      
      # API settings
      - API_PREFIX=/api/v1
      - DEBUG=false
      
      # Webhook settings
      - WEBHOOK_NOTIFICATION_URL=${WEBHOOK_NOTIFICATION_URL:-}
      
    volumes:
      # Share Scrapyd volumes for result access (optimized architecture)
      - scrapyd_items:/app/items:ro
      - scrapyd_logs:/app/logs:ro
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      scrapyd:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8001/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

  # FIXED Celery Worker with CONSISTENT credentials
  celery-worker:
    build: 
      context: .
      dockerfile: apps/celery/Dockerfile
    image: discoverybot/celery:latest
    container_name: discovery-celery-worker
    init: true
    volumes:
      - ./apps:/app/apps
      - ./apps/discovery/data:/app/data
      - ./apps/discovery/logs:/app/logs
    environment:
      # CONSISTENT RabbitMQ and Redis credentials
      - CELERY_BROKER_URL=amqp://admin:rabbitmq123@rabbitmq:5672/discovery
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - PYTHONPATH=/app
      
      # Updated queue names for optimized system
      - CELERY_QUEUES=scheduled_queue,maintenance_queue,notification_queue,health_queue
      - CELERY_CONCURRENCY=4
      - CELERY_LOGLEVEL=info
      
      # Enable events for Flower monitoring
      - CELERY_SEND_EVENTS=True
      - CELERY_SEND_TASK_SENT_EVENT=True
      
      # SIMPLIFIED MongoDB connection (no auth)
      - MONGODB_URI=mongodb://mongodb:27017/discovery
      - MONGODB_DB_NAME=discovery
      
      # CONSISTENT Scrapyd credentials
      - SCRAPYD_URL=http://scrapyd:6800
      - SCRAPYD_USERNAME=admin
      - SCRAPYD_PASSWORD=scrapyd123
      - SCRAPYD_PROJECT=discovery
      - PYTHONPATH=/app
      
      # Webhook settings
      - WEBHOOK_NOTIFICATION_URL=${WEBHOOK_NOTIFICATION_URL:-}
      
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      scrapyd:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "celery", "-A", "apps.celery.celery", "inspect", "ping"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s

  # FIXED Celery Beat with CONSISTENT credentials
  celery-beat:
    build: 
      context: .
      dockerfile: apps/celery/Dockerfile
    image: discoverybot/celery:latest
    container_name: discovery-celery-beat
    volumes:
      - ./apps:/app/apps
      - beat_db_data:/app/beat_db
    environment:
      # CONSISTENT credentials
      - CELERY_BROKER_URL=amqp://admin:rabbitmq123@rabbitmq:5672/discovery
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - CELERY_LOGLEVEL=info
      - MONGODB_URI=mongodb://mongodb:27017/discovery
      - MONGODB_DB_NAME=discovery
      - SCRAPYD_URL=http://scrapyd:6800
      - SCRAPYD_PROJECT=discovery
      - PYTHONPATH=/app
      
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      rabbitmq:
        condition: service_healthy
      celery-worker:
        condition: service_healthy
    restart: unless-stopped
    networks:
      - discovery-network
    command: >
      celery -A apps.celery.celery beat 
      --loglevel=info 
      --pidfile=/tmp/celerybeat.pid

  # FIXED Celery Flower with CONSISTENT credentials
  celery-flower:
    image: mher/flower:2.0.1
    container_name: discovery-celery-flower
    restart: unless-stopped
    ports:
      - "5555:5555"
    environment:
      # CONSISTENT RabbitMQ credentials
      - CELERY_BROKER_URL=amqp://admin:rabbitmq123@rabbitmq:5672/discovery
      - CELERY_RESULT_BACKEND=redis://redis:6379/0
      - FLOWER_BASIC_AUTH=admin:flower123
      - FLOWER_PORT=5555
      - FLOWER_ADDRESS=0.0.0.0
      - FLOWER_PERSISTENT=True
      - FLOWER_DB=/data/flower.db
      - FLOWER_ENABLE_EVENTS=True
      - FLOWER_MAX_TASKS=10000
      - FLOWER_AUTO_REFRESH=True
      
    volumes:
      - flower_data:/data
    user: "1000:1000"
    depends_on:
      rabbitmq:
        condition: service_healthy
      redis:
        condition: service_healthy
      celery-worker:
        condition: service_healthy
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "curl", "-f", "-u", "admin:flower123", "http://localhost:5555/api/workers"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 20s
    command: >
      celery 
      --broker=amqp://admin:rabbitmq123@rabbitmq:5672/discovery 
      flower 
      --address=0.0.0.0 
      --port=5555 
      --basic_auth=admin:flower123
      --persistent=True
      --db=/data/flower.db
      --max_tasks=10000
      
  # DBGate - Database management UI
  dbgate:
    image: dbgate/dbgate:latest
    container_name: dbgate-dev
    restart: unless-stopped
    ports:
      - "3100:3000"
    environment:
      - DBGATE_ADMIN_USERNAME=${DBGATE_USERNAME:-admin}
      - DBGATE_ADMIN_PASSWORD=${DBGATE_PASSWORD:-admin}
    volumes:
      - dbgate_data:/app/data
    deploy:
      resources:
        limits:
          memory: 256M
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
    networks:
      - discovery-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3000/api/status"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

networks:
  discovery-network:
    driver: bridge

volumes:
  scrapyd_eggs:
  scrapyd_items:
  scrapyd_logs:
  scrapyd_dbs:
  redis_data:
  mongodb_data:
  rabbitmq_data:
  celery_beat_data:
  beat_db_data:
    driver: local
  flower_data:
    driver: local
  dbgate_data:
    driver: local